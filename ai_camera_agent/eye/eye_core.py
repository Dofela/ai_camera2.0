# eye/eye_core.py
"""
Eye æ ¸å¿ƒæ¨¡å— - æ„ŸçŸ¥å±‚ç»Ÿä¸€å…¥å£

å·¥ä½œæµç¨‹:
1. VideoCapture é‡‡é›†è§†é¢‘å¸§
2. ObjectDetector è¿›è¡ŒYOLOæ£€æµ‹
3. StateFilter è¿‡æ»¤/å»é‡/è¿½è¸ª
4. SceneAnalyzer è°ƒç”¨VLMè¿›è¡Œåœºæ™¯ç†è§£
5. PerceptionMemory å­˜å‚¨æ„ŸçŸ¥ç»“æœ
"""
import asyncio
import logging
from typing import Optional, List, Set
import numpy as np

from common.types import PerceptionResult, DetectionResult, AnalysisResult
from eye.capture.video_capture import VideoCapture
from eye.capture.frame_buffer import FrameBuffer
from eye.detection.object_detector import ObjectDetector
from eye.filter.state_filter import StateFilter
from eye.analysis.scene_analyzer import SceneAnalyzer
from eye.memory.perception_memory import PerceptionMemory


class EyeCore:
    """
    çœ¼ç›æ ¸å¿ƒç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ„ŸçŸ¥ç»„ä»¶

    èŒè´£:
    - åè°ƒå„æ„ŸçŸ¥ç»„ä»¶çš„å·¥ä½œ
    - ç®¡ç†æ„ŸçŸ¥å¾ªç¯
    - æä¾›ç»Ÿä¸€çš„æ„ŸçŸ¥æ¥å£
    """

    def __init__(self):
        """åˆ›å»ºEyeç»„ä»¶ï¼ˆä¸è¿›è¡Œé‡åˆå§‹åŒ–ï¼‰"""
        # åªåˆ›å»ºå¯¹è±¡ï¼Œä¸å¯åŠ¨ä»»ä½•æ“ä½œ
        self.video_capture = VideoCapture()
        self.frame_buffer = FrameBuffer()
        self.object_detector = ObjectDetector()
        self.state_filter = StateFilter()
        self.scene_analyzer = SceneAnalyzer()
        self.perception_memory = PerceptionMemory()
        
        # è§†é¢‘å½•åˆ¶å™¨
        from eye.capture.video_recorder import VideoRecorder
        self.video_recorder = VideoRecorder()
        self.recording_active = False
        
        self._running = False
        self._perception_task: Optional[asyncio.Task] = None
        self._recording_task: Optional[asyncio.Task] = None
        
        # çŠ¶æ€
        self.latest_frame: Optional[np.ndarray] = None
        self.latest_timestamp: float = 0.0
        self.current_event_id: Optional[int] = None
        
        # é…ç½®
        self.target_objects: List[str] = ["person"]
        self.security_policy: str = "æ ‡å‡†æ¨¡å¼"
        self.muted_classes: Set[str] = set()
        
        logging.info("ğŸ‘ï¸ [Eye] åˆ›å»ºå®Œæˆï¼ˆæœªåˆå§‹åŒ–ï¼‰")

    async def initialize(self):
        """é‡åˆå§‹åŒ–ï¼ˆå¼‚æ­¥æ“ä½œï¼‰"""
        try:
            await self.perception_memory.connect_database()

            # éªŒè¯æ•°æ®åº“å¥åº·
            if self.perception_memory.db_manager:
                if not await self.perception_memory.db_manager.health_check():
                    raise RuntimeError("æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥")

            logging.info("ğŸ‘ï¸ [Eye] åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logging.error(f"âŒ [Eye] åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def start(self):
        """å¯åŠ¨æ„ŸçŸ¥å¾ªç¯"""
        self._running = True
        logging.info("ğŸ‘ï¸ [Eye] å¯åŠ¨æ„ŸçŸ¥å¾ªç¯...")

        # å¯åŠ¨è§†é¢‘é‡‡é›†
        capture_task = asyncio.create_task(self._capture_loop())

        # å¯åŠ¨åˆ†æå¾ªç¯
        analysis_task = asyncio.create_task(self._analysis_loop())
        
        # å¯åŠ¨å½•åˆ¶å¾ªç¯
        recording_task = asyncio.create_task(self._recording_loop())

        await asyncio.gather(capture_task, analysis_task, recording_task)

    async def stop(self):
        """åœæ­¢æ„ŸçŸ¥å¾ªç¯"""
        self._running = False
        await self.video_capture.stop()
        await self.scene_analyzer.close()
        logging.info("ğŸ‘ï¸ [Eye] æ„ŸçŸ¥å¾ªç¯å·²åœæ­¢")
    
    async def close(self):
        """å…³é—­Eyeæ ¸å¿ƒèµ„æº"""
        # å…³é—­æ•°æ®åº“è¿æ¥
        if self.perception_memory and self.perception_memory.db_manager:
            await self.perception_memory.db_manager.close_all()
        
        # å…³é—­è§†é¢‘é‡‡é›†
        await self.video_capture.stop()
        
        # å…³é—­åœºæ™¯åˆ†æå™¨
        await self.scene_analyzer.close()
        
        logging.info("ğŸ‘ï¸ [Eye] èµ„æºå·²å…³é—­")

    async def _capture_loop(self):
        """è§†é¢‘é‡‡é›†å¾ªç¯"""
        await self.video_capture.start()

        while self._running:
            frame_data = await self.video_capture.get_frame()
            if frame_data:
                self.latest_frame = frame_data["frame"]
                self.latest_timestamp = frame_data["timestamp"]
                await self.frame_buffer.add(frame_data)
                
                # å¹¿æ’­å¸§åˆ°WebSocketå®¢æˆ·ç«¯
                try:
                    from api.websockets.video_feed import manager
                    await manager.broadcast_frame(self.latest_frame)
                except Exception as e:
                    logging.debug(f"ğŸ“º WebSocketå¹¿æ’­å¤±è´¥: {e}")
                    
            await asyncio.sleep(0)

    async def _analysis_loop(self):
        """åˆ†æå¾ªç¯"""
        while self._running:
            # ç­‰å¾…æ–°å¸§
            await self.frame_buffer.wait_for_new_data()

            # è·å–å¸§åºåˆ—
            frames = await self.frame_buffer.get_frames()
            if not frames:
                continue

            # æ‰§è¡Œæ„ŸçŸ¥
            try:
                result = await self.perceive(frames)
                if result:
                    # å­˜å‚¨æ„ŸçŸ¥ç»“æœ
                    await self.perception_memory.store(result)
            except Exception as e:
                logging.error(f"ğŸ‘ï¸ [Eye] åˆ†æé”™è¯¯: {e}")

            await asyncio.sleep(0.01)
    
    async def _recording_loop(self):
        """å½•åˆ¶å¾ªç¯ - ç®¡ç†è§†é¢‘å½•åˆ¶åŸºäºäº‹ä»¶"""
        while self._running:
            # æ£€æŸ¥äº‹ä»¶æ˜¯å¦æ´»è·ƒä¸”éœ€è¦å½•åˆ¶
            if (self.perception_memory.current_event.is_active and
                self.perception_memory.current_event.event_id is not None):
                
                if not self.recording_active:
                    # å¼€å§‹å½•åˆ¶
                    event_id = self.perception_memory.current_event.event_id
                    context_frames = await self.get_context_frames()
                    
                    video_path = self.video_recorder.start_recording(
                        event_id=event_id,
                        frames=context_frames
                    )
                    
                    if video_path:
                        self.recording_active = True
                        logging.info(f"ğŸ¥ å¼€å§‹å½•åˆ¶äº‹ä»¶ {event_id}")
                
                # å‘å½•åˆ¶å™¨æ·»åŠ å¸§
                if self.recording_active and self.latest_frame is not None:
                    self.video_recorder.add_frame(self.latest_frame)
            
            elif self.recording_active:
                # åœæ­¢å½•åˆ¶å½“äº‹ä»¶å…³é—­æ—¶
                video_path = self.video_recorder.stop_recording()
                
                # æ›´æ–°æ•°æ®åº“ä¸­çš„è§†é¢‘è·¯å¾„
                if video_path and self.perception_memory.db_manager:
                    try:
                        await self.perception_memory.db_manager.update_video_path(
                            event_id=self.perception_memory.current_event.event_id,
                            video_path=video_path
                        )
                        logging.info(f"ğŸ’¾ è§†é¢‘å·²ä¿å­˜: {video_path}")
                    except Exception as e:
                        logging.error(f"âŒ æ›´æ–°è§†é¢‘è·¯å¾„å¤±è´¥: {e}")
                
                self.recording_active = False
            
            await asyncio.sleep(0.1)

    async def perceive(self, frames: List[dict]) -> Optional[PerceptionResult]:
        """
        æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ„ŸçŸ¥æµç¨‹

        Args:
            frames: å¸§æ•°æ®åˆ—è¡¨

        Returns:
            æ„ŸçŸ¥ç»“æœ
        """
        if not frames:
            return None

        latest_frame = frames[-1]["frame"]
        timestamp = frames[-1].get("timestamp", "")

        # 1. ç›®æ ‡æ£€æµ‹
        detection_result = await self.object_detector.detect(
            latest_frame,
            alert_targets=self.state_filter.high_priority_classes
        )

        # 2. è¿‡æ»¤é™éŸ³ç±»åˆ«
        if self.muted_classes:
            detection_result = self._filter_muted(detection_result)

        # 3. çŠ¶æ€è¿‡æ»¤
        should_analyze, objects_to_analyze = self.state_filter.should_trigger_vlm(
            detection_result.detections
        )

        # 4. æ„å»ºæ„ŸçŸ¥ç»“æœ
        result = PerceptionResult(
            detection_result=detection_result,
            timestamp=timestamp
        )

        # 5. å¤„ç†æ£€æµ‹ç»“æœ
        if detection_result.detections:
            # æ£€æŸ¥è§†è§‰é«˜å±
            visual_risks = self._check_visual_risks(detection_result)
            if visual_risks:
                result.alert_tags.add("visual")

            # æ›´æ–°äº‹ä»¶
            result.event_id = await self._update_event(detection_result, result.alert_tags)

            # 6. è§¦å‘VLMåˆ†æ
            if should_analyze and result.event_id:
                analysis_result = await self._run_vlm_analysis(frames, detection_result)
                if analysis_result:
                    result.analysis_result = analysis_result
                    if analysis_result.is_abnormal:
                        result.alert_tags.add("behavior")
        else:
            # æ— ç›®æ ‡ï¼Œå°è¯•å…³é—­äº‹ä»¶
            await self._try_close_event()

        return result

    async def perceive_single(self, frame: np.ndarray) -> Optional[PerceptionResult]:
        """
        å¯¹å•å¸§è¿›è¡Œæ„ŸçŸ¥ï¼ˆç”¨äºå³æ—¶æŸ¥è¯¢ï¼‰

        Args:
            frame: å•å¸§å›¾åƒ

        Returns:
            æ„ŸçŸ¥ç»“æœ
        """
        detection_result = await self.object_detector.detect(frame)

        return PerceptionResult(
            detection_result=detection_result,
            timestamp=""
        )

    def _filter_muted(self, detection_result: DetectionResult) -> DetectionResult:
        """è¿‡æ»¤é™éŸ³ç±»åˆ«"""
        filtered = [
            d for d in detection_result.detections
            if d.class_name not in self.muted_classes
        ]
        return DetectionResult(
            detections=filtered,
            frame=detection_result.frame,
            plotted_frame=detection_result.plotted_frame,
            timestamp=detection_result.timestamp
        )

    def _check_visual_risks(self, detection_result: DetectionResult) -> List[str]:
        """æ£€æŸ¥è§†è§‰é«˜å±ç›®æ ‡"""
        risks = []
        for det in detection_result.detections:
            if det.class_name in self.state_filter.high_priority_classes:
                risks.append(det.class_name)
        return risks

    async def _update_event(self, detection_result: DetectionResult, alert_tags: Set[str]) -> int:
        """æ›´æ–°æˆ–åˆ›å»ºäº‹ä»¶"""
        return await self.perception_memory.update_event(
            detection_result.class_counts,
            is_abnormal="visual" in alert_tags,
            alert_tags=alert_tags
        )

    async def _try_close_event(self):
        """å°è¯•å…³é—­å½“å‰äº‹ä»¶"""
        await self.perception_memory.try_close_event()

    async def _run_vlm_analysis(
            self,
            frames: List[dict],
            detection_result: DetectionResult
    ) -> Optional[AnalysisResult]:
        """è¿è¡ŒVLMåˆ†æ"""
        frame_list = [f["frame"] for f in frames]
        return await self.scene_analyzer.analyze(
            frames=frame_list,
            detections=detection_result.unique_classes,
            security_policy=self.security_policy
        )

    # ============================================================
    # é…ç½®æ¥å£
    # ============================================================

    def update_targets(self, targets: List[str]) -> bool:
        """æ›´æ–°æ£€æµ‹ç›®æ ‡"""
        self.target_objects = targets
        return self.object_detector.update_targets(targets)

    def update_security_policy(self, policy: str, risk_level: str = "normal"):
        """æ›´æ–°å®‰é˜²ç­–ç•¥"""
        self.security_policy = policy

        # æ›´æ–°çŠ¶æ€è¿‡æ»¤å™¨
        dynamic_targets = self.target_objects if risk_level == "high" else None
        self.state_filter.update_policy(risk_level, dynamic_targets)

    def mute_class(self, class_name: str):
        """é™éŸ³æŸä¸ªç±»åˆ«"""
        self.muted_classes.add(class_name)

    def unmute_class(self, class_name: str):
        """å–æ¶ˆé™éŸ³"""
        self.muted_classes.discard(class_name)

    # ============================================================
    # çŠ¶æ€æŸ¥è¯¢æ¥å£
    # ============================================================

    def get_latest_frame(self) -> Optional[np.ndarray]:
        """è·å–æœ€æ–°å¸§"""
        return self.latest_frame

    async def get_context_frames(self) -> List[np.ndarray]:
        """è·å–ä¸Šä¸‹æ–‡å¸§åºåˆ—"""
        frames = await self.frame_buffer.get_frames()
        return [f["frame"] for f in frames]

    def get_status(self) -> dict:
        """è·å–çœ¼ç›çŠ¶æ€"""
        return {
            "running": self._running,
            "targets": self.target_objects,
            "policy": self.security_policy,
            "muted_classes": list(self.muted_classes),
            "current_event_id": self.current_event_id
        }