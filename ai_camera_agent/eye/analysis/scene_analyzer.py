# eye/analysis/scene_analyzer.py
"""
åœºæ™¯åˆ†æå™¨ - ä½¿ç”¨VLMè¿›è¡Œåœºæ™¯ç†è§£

åŸºäºåŸ app/services/analysis_service.py ä¸­çš„ VLM è°ƒç”¨é€»è¾‘é‡æ„
"""
import json
import asyncio
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum
import numpy as np

from common.types import AnalysisResult
from eye.analysis.vlm_client import VLMClient, video_chat_async_limit_frame
from config.settings import MonitorLLMConfig, EyeConfig

class AnalysisPriority(Enum):
    LOW = 0
    NORMAL = 1
    HIGH = 2
    CRITICAL = 3

@dataclass
class AnalysisRequest:
    frames: List[np.ndarray]
    detections: List[str]
    security_policy: str
    priority: AnalysisPriority
    callback: callable


class SceneAnalyzer:
    """
    åœºæ™¯åˆ†æå™¨

    åŠŸèƒ½:
    - è°ƒç”¨VLMåˆ†æè§†é¢‘å¸§
    - è§£æVLMè¿”å›çš„JSONç»“æœ
    - åˆ¤æ–­æ˜¯å¦å­˜åœ¨å¼‚å¸¸è¡Œä¸º

    å·¥ä½œåŸç†:
    1. æ¥æ”¶å¸§åºåˆ—å’Œæ£€æµ‹ç»“æœ
    2. æ„å»ºåŒ…å«å®‰é˜²ç­–ç•¥çš„Prompt
    3. è°ƒç”¨VLMè¿›è¡Œåˆ†æ
    4. è§£æè¿”å›ç»“æœåˆ¤æ–­æ˜¯å¦å¼‚å¸¸
    """

    def __init__(self):
        self.vlm_client = VLMClient(config=MonitorLLMConfig)
        
        # å…è®¸æœ€å¤š3ä¸ªå¹¶å‘åˆ†æ
        from asyncio import Semaphore
        self.semaphore = Semaphore(3)
        
        # è¯·æ±‚é˜Ÿåˆ—
        from asyncio import Queue
        self.request_queue = Queue()
        
        # å¯åŠ¨åå°å·¥ä½œå™¨
        asyncio.create_task(self._analysis_worker())
        
        logging.info("ğŸ§  [SceneAnalyzer] åˆå§‹åŒ–å®Œæˆ")
    
    async def _analysis_worker(self):
        """åå°å·¥ä½œå™¨å¤„ç†åˆ†æè¯·æ±‚"""
        while True:
            request = await self.request_queue.get()
            
            # è·å–ä¿¡å·é‡ï¼ˆé™åˆ¶å¹¶å‘ï¼‰
            async with self.semaphore:
                try:
                    result = await self._do_analysis(
                        request.frames,
                        request.detections,
                        request.security_policy
                    )
                    request.callback(result)
                except Exception as e:
                    logging.error(f"åˆ†æå¤±è´¥: {e}")
                    request.callback(None)

    async def analyze(
            self,
            frames: List[np.ndarray],
            detections: List[str],
            security_policy: str = "æ ‡å‡†æ¨¡å¼",
            priority=AnalysisPriority.NORMAL
    ) -> Optional[AnalysisResult]:
        """
        éé˜»å¡åˆ†æè¯·æ±‚

        Args:
            frames: å¸§åºåˆ—
            detections: æ£€æµ‹åˆ°çš„ç›®æ ‡ç±»åˆ«åˆ—è¡¨
            security_policy: å½“å‰å®‰é˜²ç­–ç•¥
            priority: åˆ†æä¼˜å…ˆçº§

        Returns:
            åˆ†æç»“æœï¼Œå¦‚æœåˆ†æå¤±è´¥è¿”å›None
        """
        future = asyncio.Future()
        
        request = AnalysisRequest(
            frames=frames,
            detections=detections,
            security_policy=security_policy,
            priority=priority,
            callback=lambda result: future.set_result(result)
        )
        
        await self.request_queue.put(request)
        
        try:
            # ç­‰å¾…ç»“æœï¼ˆå¸¦è¶…æ—¶ï¼‰
            return await asyncio.wait_for(future, timeout=60.0)
        except asyncio.TimeoutError:
            logging.error("VLMåˆ†æè¶…æ—¶")
            return None
    
    async def _do_analysis(
            self,
            frames: List[np.ndarray],
            detections: List[str],
            security_policy: str
    ) -> Optional[AnalysisResult]:
        """å®é™…æ‰§è¡Œåˆ†æ"""
        try:
            # 1. æ„å»ºPrompt
            prompt = self._build_analysis_prompt(detections, security_policy)

            # 2. è°ƒç”¨VLM
            json_response = await self.vlm_client.analyze_frames(
                frames=frames,
                prompt=prompt
            )

            # 3. è§£æç»“æœ
            if not json_response or json_response == "{}":
                return None

            result = self._parse_response(json_response)
            return result
            
        except Exception as e:
            logging.error(f"âŒ [SceneAnalyzer] åˆ†æå‡ºé”™: {e}")
            return None

    async def close(self):
        """å…³é—­åˆ†æå™¨èµ„æº"""
        # å…³é—­VLMå®¢æˆ·ç«¯
        if hasattr(self.vlm_client, 'close'):
            await self.vlm_client.close()
        
        logging.info("ğŸ§  [SceneAnalyzer] å·²å…³é—­")
    
    async def analyze_single_frame(
            self,
            frame: np.ndarray,
            instruction: str = "è¯·æè¿°å½“å‰ç”»é¢"
    ) -> Optional[AnalysisResult]:
        """
        åˆ†æå•å¸§ï¼ˆç”¨äºå³æ—¶æŸ¥è¯¢ï¼‰

        Args:
            frame: å•å¸§å›¾åƒ
            instruction: åˆ†ææŒ‡ä»¤

        Returns:
            åˆ†æç»“æœ
        """
        try:
            prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªè§†è§‰åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æŒ‡ä»¤åˆ†æç”»é¢ã€‚

            ã€ç”¨æˆ·æŒ‡ä»¤ã€‘
            {instruction}

            ã€è¾“å‡ºæ ¼å¼ã€‘(ä»…è¾“å‡ºJSON):
            {{
                "description": "å¯¹ç”»é¢çš„æè¿°",
                "is_abnormal": false,
                "reason": "åˆ¤æ–­ä¾æ®"
            }}
            """

            json_response = await self.vlm_client.analyze_frames(
                frames=[frame],
                prompt=prompt
            )

            return self._parse_response(json_response)

        except Exception as e:
            logging.error(f"âŒ [SceneAnalyzer] å•å¸§åˆ†æå‡ºé”™: {e}")
            return None

    def _build_analysis_prompt(
            self,
            detections: List[str],
            security_policy: str
    ) -> str:
        """
        æ„å»ºåˆ†æPrompt

        Args:
            detections: æ£€æµ‹åˆ°çš„ç›®æ ‡
            security_policy: å®‰é˜²ç­–ç•¥

        Returns:
            å®Œæ•´çš„Prompt
        """
        yolo_hint = json.dumps(detections, ensure_ascii=False)

        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªåå°å®‰é˜²ç›‘æ§ç¨‹åºã€‚è¯·ä¾æ®ä»¥ä¸‹ã€è§†è§‰æ³•å…¸ã€‘åˆ†æç”»é¢ã€‚

        ã€å½“å‰å®‰é˜²ç­–ç•¥ (Policy)ã€‘:
        "{security_policy}"

        ã€ä¼ æ„Ÿå™¨æ•°æ®ã€‘:
        - YOLOæ£€æµ‹: {yolo_hint}

        ã€åˆ¤æ–­æ ‡å‡†ã€‘:
        1. å¦‚æœç”»é¢ä¸­çš„è¡Œä¸ºè¿åäº†ä¸Šè¿°ç­–ç•¥ (å¦‚ç¦»å®¶æ¨¡å¼å‡ºç°äºº)ï¼Œå¿…é¡»æ ‡è®° is_abnormal=trueã€‚
        2. å¯¹äº Fire, Smoke, Knife, Blood, Fallï¼Œå¿…é¡»æ ‡è®° is_abnormal=trueã€‚
        3. å¦‚æœåªæ˜¯æ­£å¸¸æ´»åŠ¨ä¸”ç¬¦åˆç­–ç•¥ï¼Œæ ‡è®° falseã€‚

        ã€è¾“å‡ºæ ¼å¼ã€‘(ä»…è¾“å‡ºJSON):
        {{
            "description": "å®¢è§‚ç®€çŸ­çš„ç”»é¢æè¿°",
            "is_abnormal": true/false,
            "reason": "åˆ¤æ–­ä¾æ®"
        }}
        """

        return prompt

    def _parse_response(self, json_response: str) -> Optional[AnalysisResult]:
        """
        è§£æVLMå“åº”

        Args:
            json_response: JSONæ ¼å¼çš„å“åº”å­—ç¬¦ä¸²

        Returns:
            è§£æåçš„AnalysisResult
        """
        try:
            # æ¸…ç†JSONå­—ç¬¦ä¸²
            clean_json = json_response.replace("```json", "").replace("```", "").strip()

            # æå–JSONéƒ¨åˆ†
            if "{" in clean_json:
                clean_json = clean_json[clean_json.find("{"):clean_json.rfind("}") + 1]

            # è§£æJSON
            res = json.loads(clean_json)

            return AnalysisResult(
                description=res.get("description", "åˆ†æå®Œæˆ"),
                is_abnormal=bool(res.get("is_abnormal", False)),
                reason=res.get("reason", ""),
                raw_response=json_response
            )

        except json.JSONDecodeError as e:
            logging.warning(f"âš ï¸ [SceneAnalyzer] JSONè§£æå¤±è´¥: {e}")
            return AnalysisResult(
                description=json_response[:100] if json_response else "è§£æå¤±è´¥",
                is_abnormal=False,
                raw_response=json_response
            )
        except Exception as e:
            logging.error(f"âŒ [SceneAnalyzer] å“åº”è§£æé”™è¯¯: {e}")
            return None

    async def close(self):
        """å…³é—­åˆ†æå™¨"""
        await self.vlm_client.close()
        logging.info("ğŸ§  [SceneAnalyzer] å·²å…³é—­")