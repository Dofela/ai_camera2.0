# infrastructure/database/async_db_manager.py
"""
å¼‚æ­¥æ•°æ®åº“ç®¡ç†å™¨ - Eye æ¨¡å—ä¸“ç”¨é«˜æ€§èƒ½å¼•æ“

æ ¸å¿ƒç‰¹æ€§:
1. åŸºäº asyncpg çš„é«˜æ€§èƒ½è¿æ¥æ± 
2. å®ç°äº† "æ–¹æ¡ˆ A" æ‰¹é‡å†™å…¥ç­–ç•¥ (Batch Writing)
   - è§‚å¯Ÿæµ (INSERT) -> ç¼“å†²é˜Ÿåˆ— -> æ‰¹é‡æäº¤
   - äº‹ä»¶æ›´æ–° (UPDATE) -> ç¼“å†²é˜Ÿåˆ— -> æ‰¹é‡æäº¤
3. æ”¯æŒ JSONB å’Œ Vector æ•°æ®çš„é«˜æ•ˆå­˜å‚¨
"""

import asyncio
import json
import logging
from typing import Dict, List, Optional, Any, Tuple
import asyncpg
from datetime import datetime

from config.settings import DBConfig


class AsyncDBManager:
    """
    Eye æ¨¡å—ä¸“ç”¨å¼‚æ­¥æ•°æ®åº“ç®¡ç†å™¨ (å•ä¾‹æ¨¡å¼)

    èŒè´£:
    1. ç®¡ç† Eye æ¨¡å—çš„é«˜é¢‘å†™å…¥ (Vectors, Observations)
    2. ç»´æŠ¤æ‰¹é‡å†™å…¥é˜Ÿåˆ—ï¼Œé˜²æ­¢ I/O é˜»å¡
    """

    _instance = None
    _lock = asyncio.Lock()

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(AsyncDBManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self.pool: Optional[asyncpg.Pool] = None

        # æ‰¹é‡å†™å…¥é…ç½®
        self.batch_size = 50        # æ‰¹æ¬¡å¤§å°
        self.flush_interval = 1.0   # åˆ·æ–°é—´éš”(ç§’)

        # ç¼“å†²é˜Ÿåˆ—
        # é˜Ÿåˆ—é¡¹: (sql, params_tuple)
        self._obs_queue = asyncio.Queue()     # è§‚å¯Ÿæµé˜Ÿåˆ—
        self._update_queue = asyncio.Queue()  # äº‹ä»¶æ›´æ–°é˜Ÿåˆ—

        self._worker_task: Optional[asyncio.Task] = None
        self._running = False

        self._initialized = True
        logging.info("ğŸš€ [AsyncDBManager] å¼‚æ­¥å¼•æ“åˆå§‹åŒ– (AsyncPG + Batching)")

    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥æ± å¹¶å¯åŠ¨åå° Worker"""
        async with self._lock:
            if self.pool:
                return

            try:
                # åˆ›å»ºè¿æ¥æ± 
                # è‡ªåŠ¨å°† json è½¬æ¢æ³¨å†Œåˆ°è¿æ¥ä¸­ï¼Œæ–¹ä¾¿ JSONB å­˜å–
                self.pool = await asyncpg.create_pool(
                    dsn=DBConfig.DATABASE_URL,
                    min_size=DBConfig.EYE_POOL_MIN_SIZE,
                    max_size=DBConfig.EYE_POOL_MAX_SIZE,
                    init=self._init_connection
                )

                # å¯åŠ¨åå°æ‰¹å¤„ç† Worker
                self._running = True
                self._worker_task = asyncio.create_task(self._batch_worker())

                logging.info(f"âœ… [AsyncDBManager] è¿æ¥æ± å°±ç»ª: {DBConfig.EYE_POOL_MIN_SIZE}-{DBConfig.EYE_POOL_MAX_SIZE} Conns")

            except Exception as e:
                logging.critical(f"âŒ [AsyncDBManager] åˆå§‹åŒ–å¤±è´¥: {e}")
                raise

    async def _init_connection(self, conn):
        """è¿æ¥åˆå§‹åŒ–é’©å­: é…ç½® JSONB ç¼–è§£ç """
        await conn.set_type_codec(
            'jsonb',
            encoder=json.dumps,
            decoder=json.loads,
            schema='pg_catalog'
        )

    # ============================================================
    # æ ¸å¿ƒå†™æ“ä½œ (ä¸šåŠ¡æ¥å£)
    # ============================================================

    async def start_event(self, start_time: str, initial_targets: Dict[str, int],
                         is_abnormal: bool = False, alert_tags: str = "",
                         refine_data: List[Dict] = None) -> Optional[int]:
        """
        å¼€å§‹æ–°äº‹ä»¶ (åŒæ­¥ç­‰å¾…è¿”å› ID)

        æ³¨æ„: start_event ä¸èƒ½æ‰¹å¤„ç†ï¼Œå› ä¸ºä¸šåŠ¡å±‚ç«‹å³éœ€è¦ event_id
        """
        if not self.pool:
            logging.error("âŒ DBæœªè¿æ¥")
            return None

        summary = self._fmt_summary(initial_targets)
        # asyncpg ä¼šè‡ªåŠ¨å¤„ç† dict/list -> jsonb çš„è½¬æ¢
        refine_payload = refine_data if refine_data else []

        sql = """
        INSERT INTO security_events 
        (start_time, end_time, status, target_data, sys_summary, is_abnormal, alert_tags, refine_data)
        VALUES ($1, $2, 'ongoing', $3, $4, $5, $6, $7)
        RETURNING id
        """

        try:
            async with self.pool.acquire() as conn:
                row = await conn.fetchrow(
                    sql,
                    datetime.fromisoformat(start_time) if isinstance(start_time, str) else start_time,
                    datetime.fromisoformat(start_time) if isinstance(start_time, str) else start_time,
                    initial_targets,
                    summary,
                    is_abnormal,
                    alert_tags,
                    refine_payload
                )
                event_id = row['id']
                logging.info(f"ğŸ“ [AsyncDBManager] äº‹ä»¶åˆ›å»º: ID={event_id} (å®æ—¶)")
                return event_id
        except Exception as e:
            logging.error(f"âŒ [AsyncDBManager] Start Event å¤±è´¥: {e}")
            return None

    async def update_event(self, row_id: int, end_time: str, max_targets: Dict[str, int],
                          is_abnormal: Optional[bool] = None, alert_tags: Optional[str] = None,
                          refine_data: List[Dict] = None):
        """
        æ›´æ–°äº‹ä»¶ (è¿›å…¥æ‰¹é‡é˜Ÿåˆ—)

        æ ¸å¿ƒä¼˜åŒ–: è¿™æ˜¯é«˜é¢‘æ“ä½œï¼Œä½¿ç”¨ "æ–¹æ¡ˆ A" æ”¾å…¥é˜Ÿåˆ—ï¼Œåå°æ‰¹é‡ UPDATE
        """
        if not self.pool: return

        # æ„å»º UPDATE è¯­å¥
        # ä¸ºäº†æ”¯æŒ executemanyï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªç»Ÿä¸€çš„ SQL æ¨¡æ¿
        # è¿™é‡Œçš„ç­–ç•¥æ˜¯ï¼šå³ä½¿æŸäº›å­—æ®µä¸æ›´æ–°ï¼Œä¹Ÿä¼ å…¥å½“å‰å€¼ï¼ˆç”±ä¸šåŠ¡å±‚ä¿è¯ï¼‰
        # ä½†ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬è¿™é‡Œé’ˆå¯¹æœ€å¸¸è§çš„é«˜é¢‘æ›´æ–°åœºæ™¯ä¼˜åŒ–ï¼šæ›´æ–°æ—¶é—´å’Œç›®æ ‡æ•°æ®

        # å¦‚æœæœ‰ refine_data (å‘é‡æ•°æ®)ï¼Œè¿™æ˜¯æœ€â€œé‡â€çš„æ“ä½œï¼Œå¿…é¡»è¿›é˜Ÿåˆ—

        target_json = max_targets
        summary = self._fmt_summary(max_targets)
        refine_payload = refine_data if refine_data else []

        # åŠ¨æ€æ„å»º SQL æ¯”è¾ƒéº»çƒ¦ï¼Œå¯¹äºæ‰¹å¤„ç†ï¼Œæœ€å¥½å›ºå®š SQL
        # è¿™é‡Œæˆ‘ä»¬å‡è®¾ update_event æ€»æ˜¯æ›´æ–° end_time, target_data, sys_summary
        # is_abnormal, alert_tags, refine_data æ˜¯å¯é€‰æ›´æ–°

        # ä¸ºäº†ç®€åŒ–æ‰¹å¤„ç†é€»è¾‘ï¼Œæˆ‘ä»¬ä½¿ç”¨ COALESCE æˆ–è€…åœ¨ Python å±‚å¤„ç†
        # è¿™é‡Œé‡‡ç”¨ä¸€ä¸ªé€šç”¨ SQLï¼Œæ‰€æœ‰å­—æ®µéƒ½ä¼ 

        sql = """
        UPDATE security_events SET 
            end_time = $1, 
            target_data = $2, 
            sys_summary = $3,
            is_abnormal = COALESCE($4, is_abnormal),
            alert_tags = COALESCE($5, alert_tags),
            refine_data = CASE WHEN $6::jsonb IS NOT NULL THEN $6::jsonb ELSE refine_data END
        WHERE id = $7
        """

        params = (
            datetime.fromisoformat(end_time) if isinstance(end_time, str) else end_time,
            target_json,
            summary,
            is_abnormal,
            alert_tags,
            refine_payload if refine_data is not None else None, # æ³¨æ„: None åœ¨ SQL ä¸­æ˜¯ NULL
            row_id
        )

        # æ”¾å…¥é˜Ÿåˆ— (Fire & Forget)
        try:
            self._update_queue.put_nowait((sql, params))
        except asyncio.QueueFull:
            logging.warning("âš ï¸ [AsyncDBManager] æ›´æ–°é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ›´æ–°")

    async def insert_observation(self, content: str, target: str = "unknown"):
        """
        æ’å…¥è§‚å¯Ÿæ—¥å¿— (è¿›å…¥æ‰¹é‡é˜Ÿåˆ—)

        æ ¸å¿ƒä¼˜åŒ–: å…¸å‹çš„æ—¥å¿—æµï¼Œæœ€é€‚åˆæ‰¹é‡ INSERT
        """
        sql = "INSERT INTO observation_stream (content, target, timestamp) VALUES ($1, $2, CURRENT_TIMESTAMP)"
        params = (content, target)

        try:
            self._obs_queue.put_nowait((sql, params))
        except asyncio.QueueFull:
            pass # æ—¥å¿—ä¸¢å¼ƒä¸å½±å“ä¸»æµç¨‹

    async def close_event(self, row_id: int, end_time: str):
        """å…³é—­äº‹ä»¶ (å®æ—¶æ‰§è¡Œ)"""
        if not self.pool: return

        sql = "UPDATE security_events SET status = 'closed', end_time = $1 WHERE id = $2"
        try:
            async with self.pool.acquire() as conn:
                await conn.execute(sql, datetime.fromisoformat(end_time) if isinstance(end_time, str) else end_time, row_id)
                logging.info(f"ğŸ“ [AsyncDBManager] äº‹ä»¶å…³é—­: ID={row_id}")
        except Exception as e:
            logging.error(f"âŒ [AsyncDBManager] Close Event å¤±è´¥: {e}")

    async def update_video_path(self, event_id: int, video_path: str):
        """æ›´æ–°è§†é¢‘è·¯å¾„ (å®æ—¶æ‰§è¡Œ)"""
        if not self.pool: return
        sql = "UPDATE security_events SET video_path = $1 WHERE id = $2"
        try:
            async with self.pool.acquire() as conn:
                await conn.execute(sql, video_path, event_id)
        except Exception as e:
            logging.error(f"âŒ æ›´æ–°è§†é¢‘è·¯å¾„å¤±è´¥: {e}")

    # ============================================================
    # åå°æ‰¹å¤„ç† Worker (æ–¹æ¡ˆ A æ ¸å¿ƒ)
    # ============================================================

    async def _batch_worker(self):
        """
        åå° Worker: å®šæœŸä»é˜Ÿåˆ—å–å‡ºæ•°æ®å¹¶æ‰¹é‡æ‰§è¡Œ
        """
        logging.info("âš™ï¸ [AsyncDBManager] æ‰¹å¤„ç† Worker å·²å¯åŠ¨")

        while self._running:
            try:
                # 1. å¤„ç†è§‚å¯Ÿæµ (INSERTs)
                await self._flush_queue(self._obs_queue, "è§‚å¯Ÿæµ")

                # 2. å¤„ç†äº‹ä»¶æ›´æ–° (UPDATEs)
                await self._flush_queue(self._update_queue, "äº‹ä»¶æ›´æ–°")

                # ä¼‘çœ 
                await asyncio.sleep(self.flush_interval)

            except Exception as e:
                logging.error(f"âŒ [AsyncDBManager] Worker å¼‚å¸¸: {e}")
                await asyncio.sleep(1.0)

    async def _flush_queue(self, queue: asyncio.Queue, name: str):
        """é€šç”¨é˜Ÿåˆ—åˆ·æ–°é€»è¾‘"""
        if queue.empty():
            return

        batch_data = []
        sql_template = None

        # å–å‡ºå½“å‰é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰é¡¹ (ä¸Šé™ batch_size)
        for _ in range(self.batch_size):
            if queue.empty():
                break

            try:
                item = queue.get_nowait()
                sql, params = item

                # ç®€å•çš„æ‰¹å¤„ç†è¦æ±‚ SQL è¯­å¥å¿…é¡»ä¸€è‡´
                if sql_template is None:
                    sql_template = sql
                elif sql != sql_template:
                    # å¦‚æœé‡åˆ°ä¸åŒçš„ SQLï¼Œå…ˆå¤„ç†å½“å‰çš„æ‰¹æ¬¡ï¼Œå‰©ä¸‹çš„æ”¾å›æˆ–è¿™å°±æäº¤
                    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªå¤„ç†ç›¸åŒ SQL çš„æ‰¹æ¬¡ (é€šå¸¸åŒä¸ªé˜Ÿåˆ— SQL æ˜¯ä¸€æ ·çš„)
                    # å®é™…ç”Ÿäº§ä¸­å¯èƒ½éœ€è¦æŒ‰ SQL åˆ†ç»„
                    logging.warning(f"âš ï¸ [AsyncDBManager] {name} SQL ä¸ä¸€è‡´ï¼Œè·³è¿‡æ‰¹å¤„ç†ä¼˜åŒ–")
                    # è¿™é‡Œç®€å•çš„å¤„ç†ï¼šå¦‚æœ SQL ä¸åŒï¼Œå›é€€è¯¥ item å¹¶åœæ­¢æœ¬è½®
                    # ä½†ä¸ºäº†ä¸é˜»å¡ï¼Œæˆ‘ä»¬å‡è®¾åŒä¸ªé˜Ÿåˆ—çš„ SQL æ˜¯ä¸€è‡´çš„ (ç”±è°ƒç”¨æ–¹ä¿è¯)
                    pass

                batch_data.append(params)
                queue.task_done()

            except Exception:
                break

        if not batch_data or not sql_template:
            return

        # æ‰§è¡Œæ‰¹é‡æ“ä½œ
        try:
            async with self.pool.acquire() as conn:
                # executemany æ˜¯ asyncpg çš„é«˜æ€§èƒ½åˆ©å™¨
                await conn.executemany(sql_template, batch_data)
                logging.debug(f"âš¡ [AsyncDBManager] {name} æ‰¹é‡æäº¤: {len(batch_data)} æ¡")
        except Exception as e:
            logging.error(f"âŒ [AsyncDBManager] {name} æ‰¹é‡æäº¤å¤±è´¥: {e}")
            # å¤±è´¥å¤„ç†: å…³é”®æ•°æ®å¯èƒ½éœ€è¦é‡è¯•ï¼Œä½†æ—¥å¿—æ•°æ®å¯ä¸¢å¼ƒ

    # ============================================================
    # è¾…åŠ©æ–¹æ³•
    # ============================================================

    def _fmt_summary(self, targets: Dict[str, int]) -> str:
        if not targets: return "æ— ç›®æ ‡"
        parts = [f"{k}({v})" for k, v in targets.items()]
        return "å‘ç°: " + ", ".join(parts)

    async def health_check(self) -> bool:
        if not self.pool: return False
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("SELECT 1")
            return True
        except:
            return False

    async def close_all(self):
        """å…³é—­èµ„æº"""
        self._running = False
        if self._worker_task:
            self._worker_task.cancel()
            try:
                await self._worker_task
            except asyncio.CancelledError:
                pass

        if self.pool:
            await self.pool.close()
            logging.info("ğŸ”’ [AsyncDBManager] è¿æ¥æ± å·²å…³é—­")

# å…¨å±€å®ä¾‹
async_db_manager = AsyncDBManager()