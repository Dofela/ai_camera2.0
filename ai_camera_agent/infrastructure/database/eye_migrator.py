# infrastructure/database/eye_migrator.py
"""
çœ¼ç›æ¨¡å—æ•°æ®åº“è¿ç§»å·¥å…·

åŠŸèƒ½:
1. ä»ç°æœ‰ä¸»æ•°æ®åº“è¯»å–è¡¨ç»“æ„
2. åˆ›å»ºæ–°çš„ eye_module.db æ•°æ®åº“
3. åˆå§‹åŒ–è¡¨ç»“æ„å’Œç´¢å¼•
4. æä¾›çŠ¶æ€æ£€æŸ¥å’Œå›æ»šæœºåˆ¶
"""

import asyncio
import json
import logging
import os
import sqlite3
import aiosqlite
from typing import Dict, List, Optional, Any
from datetime import datetime
from pathlib import Path

from config.settings import DBConfig


class EyeDatabaseMigrator:
    """
    çœ¼ç›æ¨¡å—æ•°æ®åº“è¿ç§»å·¥å…·
    
    è¿ç§»æµç¨‹:
    1. è¯»å–æºæ•°æ®åº“è¡¨ç»“æ„
    2. åˆ›å»ºç›®æ ‡æ•°æ®åº“æ–‡ä»¶
    3. åˆ›å»ºè¡¨ç»“æ„
    4. åˆ›å»ºç´¢å¼•
    5. éªŒè¯è¿ç§»ç»“æœ
    6. æ›´æ–°é…ç½®ï¼ˆå¯é€‰ï¼‰
    """
    
    def __init__(self, source_db_path: str = None, target_db_path: str = None):
        """
        åˆå§‹åŒ–è¿ç§»å·¥å…·
        
        Args:
            source_db_path: æºæ•°æ®åº“è·¯å¾„ï¼ˆä¸»æ•°æ®åº“ï¼‰
            target_db_path: ç›®æ ‡æ•°æ®åº“è·¯å¾„ï¼ˆçœ¼ç›æ¨¡å—æ•°æ®åº“ï¼‰
        """
        self.source_db_path = source_db_path or DBConfig.DB_PATH
        self.target_db_path = target_db_path or DBConfig.EYE_DB_PATH
        
        # è¿ç§»çŠ¶æ€
        self.migration_steps = []
        self.current_step = 0
        self.is_rolled_back = False
        
        # é”™è¯¯å¤„ç†é…ç½®
        self.max_retries = 3
        self.retry_delay = 0.5
        
        logging.info(f"ğŸ”„ [EyeMigrator] è¿ç§»å·¥å…·åˆå§‹åŒ–: {self.source_db_path} -> {self.target_db_path}")
    
    async def migrate(self) -> bool:
        """
        æ‰§è¡Œå®Œæ•´è¿ç§»æµç¨‹
        
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        try:
            self.migration_steps = []
            self.current_step = 0
            self.is_rolled_back = False
            
            # å®šä¹‰è¿ç§»æ­¥éª¤
            steps = [
                ("æ£€æŸ¥æºæ•°æ®åº“", self._check_source_database),
                ("è¯»å–è¡¨ç»“æ„", self._read_source_schema),
                ("åˆ›å»ºç›®æ ‡æ•°æ®åº“", self._create_target_database),
                ("åˆ›å»ºè¡¨ç»“æ„", self._create_tables),
                ("åˆ›å»ºç´¢å¼•", self._create_indexes),
                ("éªŒè¯è¿ç§»ç»“æœ", self._validate_migration),
            ]
            
            # æ‰§è¡Œæ¯ä¸ªæ­¥éª¤
            for step_name, step_func in steps:
                self.current_step += 1
                logging.info(f"ğŸ”„ [EyeMigrator] æ­¥éª¤ {self.current_step}/{len(steps)}: {step_name}")
                
                success = await self._execute_with_retry(step_func, step_name)
                if not success:
                    logging.error(f"âŒ [EyeMigrator] æ­¥éª¤å¤±è´¥: {step_name}")
                    await self.rollback()
                    return False
                
                self.migration_steps.append({
                    "step": step_name,
                    "status": "completed",
                    "timestamp": datetime.now().isoformat()
                })
            
            logging.info("âœ… [EyeMigrator] æ•°æ®åº“è¿ç§»å®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] è¿ç§»è¿‡ç¨‹å¼‚å¸¸: {e}")
            await self.rollback()
            return False
    
    async def _execute_with_retry(self, func, step_name: str) -> bool:
        """å¸¦é‡è¯•çš„æ‰§è¡Œå‡½æ•°"""
        for attempt in range(self.max_retries):
            try:
                return await func()
            except Exception as e:
                if attempt == self.max_retries - 1:
                    logging.error(f"âŒ [EyeMigrator] {step_name} å¤±è´¥ (å°è¯• {attempt + 1} æ¬¡): {e}")
                    raise
                
                delay = self.retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                logging.warning(f"âš ï¸ [EyeMigrator] {step_name} å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•: {e}")
                await asyncio.sleep(delay)
        
        return False
    
    async def _check_source_database(self) -> bool:
        """æ£€æŸ¥æºæ•°æ®åº“æ˜¯å¦å¯è®¿é—®"""
        try:
            if not os.path.exists(self.source_db_path):
                logging.warning(f"âš ï¸ [EyeMigrator] æºæ•°æ®åº“ä¸å­˜åœ¨: {self.source_db_path}")
                # å¦‚æœæºæ•°æ®åº“ä¸å­˜åœ¨ï¼Œä»ç„¶å¯ä»¥ç»§ç»­ï¼ˆåˆ›å»ºç©ºæ•°æ®åº“ï¼‰
                return True
            
            # æµ‹è¯•è¿æ¥
            conn = sqlite3.connect(self.source_db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦çš„è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            required_tables = {"security_events", "observation_stream"}
            existing_tables = set(tables)
            
            logging.info(f"ğŸ“Š [EyeMigrator] æºæ•°æ®åº“è¡¨: {tables}")
            
            conn.close()
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] æ£€æŸ¥æºæ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    async def _read_source_schema(self) -> bool:
        """è¯»å–æºæ•°æ®åº“è¡¨ç»“æ„"""
        try:
            if not os.path.exists(self.source_db_path):
                # å¦‚æœæºæ•°æ®åº“ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è¡¨ç»“æ„
                self.table_schemas = self._get_default_schemas()
                logging.info("ğŸ“‹ [EyeMigrator] ä½¿ç”¨é»˜è®¤è¡¨ç»“æ„")
                return True
            
            conn = sqlite3.connect(self.source_db_path)
            cursor = conn.cursor()
            
            # è¯»å–è¡¨ç»“æ„
            self.table_schemas = {}
            
            # è·å–æ‰€æœ‰è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            for table in tables:
                if table in ["security_events", "observation_stream"]:
                    # è·å–å»ºè¡¨è¯­å¥
                    cursor.execute(f"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table}'")
                    result = cursor.fetchone()
                    if result:
                        self.table_schemas[table] = result[0]
            
            # è·å–ç´¢å¼•
            self.index_schemas = []
            cursor.execute("SELECT sql FROM sqlite_master WHERE type='index' AND sql IS NOT NULL")
            indexes = cursor.fetchall()
            for index in indexes:
                self.index_schemas.append(index[0])
            
            conn.close()
            
            logging.info(f"ğŸ“‹ [EyeMigrator] è¯»å–åˆ° {len(self.table_schemas)} ä¸ªè¡¨ç»“æ„")
            logging.info(f"ğŸ“‹ [EyeMigrator] è¯»å–åˆ° {len(self.index_schemas)} ä¸ªç´¢å¼•")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] è¯»å–è¡¨ç»“æ„å¤±è´¥: {e}")
            raise
    
    def _get_default_schemas(self) -> Dict[str, str]:
        """è·å–é»˜è®¤è¡¨ç»“æ„ï¼ˆå½“æºæ•°æ®åº“ä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰"""
        return {
            "security_events": """
                CREATE TABLE security_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    status TEXT DEFAULT 'ongoing',
                    
                    start_time TEXT,
                    end_time TEXT,
                    
                    target_data TEXT,    -- JSON: {"person": 3, "fire": 1}
                    sys_summary TEXT,    -- ç³»ç»Ÿæè¿°
                    ai_analysis TEXT,    -- LLM æè¿°
                    
                    is_abnormal INTEGER DEFAULT 0, -- 0:æ­£å¸¸, 1:å¼‚å¸¸
                    alert_tags TEXT,     -- "visual,behavior" (é€—å·åˆ†éš”)
                    
                    snapshot_path TEXT,
                    video_path TEXT      -- æŠ¥è­¦è§†é¢‘è·¯å¾„
                )
            """,
            "observation_stream": """
                CREATE TABLE observation_stream (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    content TEXT,
                    target TEXT
                )
            """
        }
    
    async def _create_target_database(self) -> bool:
        """åˆ›å»ºç›®æ ‡æ•°æ®åº“æ–‡ä»¶"""
        try:
            # æ£€æŸ¥ç›®æ ‡æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(self.target_db_path):
                logging.warning(f"âš ï¸ [EyeMigrator] ç›®æ ‡æ•°æ®åº“å·²å­˜åœ¨: {self.target_db_path}")
                # å¤‡ä»½åŸæ–‡ä»¶
                backup_path = f"{self.target_db_path}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                import shutil
                shutil.copy2(self.target_db_path, backup_path)
                logging.info(f"ğŸ“¦ [EyeMigrator] å·²å¤‡ä»½åŸæ•°æ®åº“: {backup_path}")
            
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
            target_dir = os.path.dirname(self.target_db_path)
            if target_dir and not os.path.exists(target_dir):
                os.makedirs(target_dir, exist_ok=True)
            
            # åˆ›å»ºç©ºæ•°æ®åº“æ–‡ä»¶
            async with aiosqlite.connect(self.target_db_path) as conn:
                # å¯ç”¨WALæ¨¡å¼
                await conn.execute("PRAGMA journal_mode=WAL;")
                await conn.execute("PRAGMA synchronous=NORMAL;")
                await conn.execute("PRAGMA foreign_keys=ON;")
                await conn.commit()
            
            logging.info(f"âœ… [EyeMigrator] ç›®æ ‡æ•°æ®åº“åˆ›å»ºå®Œæˆ: {self.target_db_path}")
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] åˆ›å»ºç›®æ ‡æ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    async def _create_tables(self) -> bool:
        """åœ¨ç›®æ ‡æ•°æ®åº“åˆ›å»ºè¡¨"""
        try:
            async with aiosqlite.connect(self.target_db_path) as conn:
                for table_name, create_sql in self.table_schemas.items():
                    # ç¡®ä¿SQLè¯­å¥æ˜¯æœ‰æ•ˆçš„
                    if create_sql:
                        await conn.execute(create_sql)
                        logging.info(f"ğŸ“Š [EyeMigrator] åˆ›å»ºè¡¨: {table_name}")
                
                await conn.commit()
            
            logging.info(f"âœ… [EyeMigrator] è¡¨ç»“æ„åˆ›å»ºå®Œæˆ: {len(self.table_schemas)} ä¸ªè¡¨")
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] åˆ›å»ºè¡¨å¤±è´¥: {e}")
            raise
    
    async def _create_indexes(self) -> bool:
        """åˆ›å»ºç´¢å¼•"""
        try:
            if not hasattr(self, 'index_schemas') or not self.index_schemas:
                # åˆ›å»ºé»˜è®¤ç´¢å¼•
                self.index_schemas = [
                    "CREATE INDEX IF NOT EXISTS idx_status ON security_events (status);",
                    "CREATE INDEX IF NOT EXISTS idx_start_time ON security_events (start_time);",
                    "CREATE INDEX IF NOT EXISTS idx_abnormal ON security_events (is_abnormal);",
                    "CREATE INDEX IF NOT EXISTS idx_alert_tags ON security_events (alert_tags);"
                ]
            
            async with aiosqlite.connect(self.target_db_path) as conn:
                for index_sql in self.index_schemas:
                    if index_sql:
                        await conn.execute(index_sql)
                
                await conn.commit()
            
            logging.info(f"âœ… [EyeMigrator] ç´¢å¼•åˆ›å»ºå®Œæˆ: {len(self.index_schemas)} ä¸ªç´¢å¼•")
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
            raise
    
    async def _validate_migration(self) -> bool:
        """éªŒè¯è¿ç§»ç»“æœ"""
        try:
            async with aiosqlite.connect(self.target_db_path) as conn:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                cursor = await conn.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in await cursor.fetchall()]
                await cursor.close()
                
                required_tables = set(self.table_schemas.keys())
                existing_tables = set(tables)
                
                missing_tables = required_tables - existing_tables
                if missing_tables:
                    logging.error(f"âŒ [EyeMigrator] ç¼ºå¤±è¡¨: {missing_tables}")
                    return False
                
                # æ£€æŸ¥ç´¢å¼•
                cursor = await conn.execute("SELECT name FROM sqlite_master WHERE type='index'")
                indexes = [row[0] for row in await cursor.fetchall()]
                await cursor.close()
                
                # åŸºæœ¬å¥åº·æ£€æŸ¥
                cursor = await conn.execute("SELECT 1")
                result = await cursor.fetchone()
                await cursor.close()
                
                if not result or result[0] != 1:
                    logging.error("âŒ [EyeMigrator] å¥åº·æ£€æŸ¥å¤±è´¥")
                    return False
            
            logging.info(f"âœ… [EyeMigrator] è¿ç§»éªŒè¯é€šè¿‡: {len(tables)} ä¸ªè¡¨, {len(indexes)} ä¸ªç´¢å¼•")
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] è¿ç§»éªŒè¯å¤±è´¥: {e}")
            raise
    
    async def rollback(self) -> bool:
        """
        å›æ»šè¿ç§»
        
        åˆ é™¤å·²åˆ›å»ºçš„æ•°æ®åº“æ–‡ä»¶ï¼Œæ¢å¤ç³»ç»ŸçŠ¶æ€
        """
        try:
            if self.is_rolled_back:
                logging.info("ğŸ”„ [EyeMigrator] å›æ»šå·²å®Œæˆï¼Œè·³è¿‡")
                return True
            
            # åˆ é™¤ç›®æ ‡æ•°æ®åº“æ–‡ä»¶
            if os.path.exists(self.target_db_path):
                os.remove(self.target_db_path)
                logging.info(f"ğŸ—‘ï¸ [EyeMigrator] å·²åˆ é™¤ç›®æ ‡æ•°æ®åº“: {self.target_db_path}")
            
            self.is_rolled_back = True
            logging.info("âœ… [EyeMigrator] å›æ»šå®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"âŒ [EyeMigrator] å›æ»šå¤±è´¥: {e}")
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–è¿ç§»çŠ¶æ€"""
        return {
            "source_db": self.source_db_path,
            "target_db": self.target_db_path,
            "current_step": self.current_step,
            "total_steps": len(self.migration_steps) if hasattr(self, 'migration_steps') else 0,
            "steps": self.migration_steps if hasattr(self, 'migration_steps') else [],
            "is_rolled_back": self.is_rolled_back,
            "table_count": len(self.table_schemas) if hasattr(self, 'table_schemas') else 0,
            "index_count": len(self.index_schemas) if hasattr(self, 'index_schemas') else 0,
        }


# ä¾¿æ·å‡½æ•°
async def migrate_eye_database() -> bool:
    """æ‰§è¡Œçœ¼ç›æ¨¡å—æ•°æ®åº“è¿ç§»ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    migrator = EyeDatabaseMigrator()
    return await migrator.migrate()


async def check_eye_database() -> Dict[str, Any]:
    """æ£€æŸ¥çœ¼ç›æ¨¡å—æ•°æ®åº“çŠ¶æ€"""
    migrator = EyeDatabaseMigrator()
    
    status = {
        "source_exists": os.path.exists(migrator.source_db_path),
        "target_exists": os.path.exists(migrator.target_db_path),
        "config": {
            "eye_db_path": DBConfig.EYE_DB_PATH,
            "main_db_path": DBConfig.DB_PATH,
        }
    }
    
    # æ£€æŸ¥ç›®æ ‡æ•°æ®åº“ç»“æ„
    if status["target_exists"]:
        try:
            async with aiosqlite.connect(migrator.target_db_path) as conn:
                cursor = await conn.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in await cursor.fetchall()]
                await cursor.close()
                
                status["tables"] = tables
                status["table_count"] = len(tables)
                
                cursor = await conn.execute("SELECT name FROM sqlite_master WHERE type='index'")
                indexes = [row[0] for row in await cursor.fetchall()]
                await cursor.close()
                
                status["indexes"] = indexes
                status["index_count"] = len(indexes)
                
        except Exception as e:
            status["error"] = str(e)
    
    return status