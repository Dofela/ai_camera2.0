# infrastructure/database/db_manager.py
"""
æ•°æ®åº“ç®¡ç†å™¨ (åŒæ­¥ç‰ˆ) - åŸºäº PostgreSQL é‡æ„

èŒè´£:
1. æä¾› Web API å’Œ åå°ç®¡ç†ä»»åŠ¡ çš„æ•°æ®åº“è®¿é—®
2. ç³»ç»Ÿå¯åŠ¨æ—¶çš„è¡¨ç»“æ„åˆå§‹åŒ–
3. è¿æ¥æ± ç®¡ç† (psycopg2)
"""
import logging
import json
import threading
from typing import Dict, List, Optional, Any, Generator
from contextlib import contextmanager
import psycopg2
from psycopg2 import pool
from psycopg2.extras import RealDictCursor, Json
from config.settings import DBConfig
from infrastructure.database import schemas


class DBManager:
    """PostgreSQL æ•°æ®åº“ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""

    _instance = None
    _lock = threading.Lock()
    _pool = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super(DBManager, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self._init_pool()
        self._init_tables()
        self._initialized = True
        logging.info(f"ğŸ˜ [DBManager] PostgreSQL å°±ç»ª: {DBConfig.HOST}:{DBConfig.PORT}/{DBConfig.DB_NAME}")

    def _init_pool(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        try:
            self._pool = psycopg2.pool.SimpleConnectionPool(
                minconn=DBConfig.POOL_MIN_SIZE,
                maxconn=DBConfig.POOL_MAX_SIZE,
                dsn=DBConfig.DATABASE_URL
            )
        except Exception as e:
            logging.critical(f"âŒ [DBManager] è¿æ¥æ± åˆ›å»ºå¤±è´¥: {e}")
            raise

    def _init_tables(self):
        """åˆå§‹åŒ–è¡¨ç»“æ„ (è°ƒç”¨ schemas å®šä¹‰)"""
        with self.get_cursor() as cur:
            try:
                for sql in schemas.get_init_sqls():
                    cur.execute(sql)
                logging.info("âœ… [DBManager] è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ (å« Vector æ‰©å±•)")
            except Exception as e:
                logging.error(f"âŒ [DBManager] å»ºè¡¨å¤±è´¥: {e}")
                raise

    @contextmanager
    def get_cursor(self, commit: bool = True) -> Generator[Any, None, None]:
        """
        è·å–æ•°æ®åº“æ¸¸æ ‡çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        è‡ªåŠ¨å¤„ç†è¿æ¥çš„è·å–(Get)å’Œå½’è¿˜(Put)
        """
        conn = None
        try:
            conn = self._pool.getconn()
            # ä½¿ç”¨ RealDictCursor è®©æŸ¥è¯¢ç»“æœè¿”å›å­—å…¸è€Œéå…ƒç»„
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                yield cur
                if commit:
                    conn.commit()
        except Exception as e:
            if conn:
                conn.rollback()
            logging.error(f"âŒ [DBManager] æ•°æ®åº“æ“ä½œå¼‚å¸¸: {e}")
            raise
        finally:
            if conn:
                self._pool.putconn(conn)

    # ============================================================
    # æ ¸å¿ƒè¯»å†™æ“ä½œ (åŒæ­¥æ¥å£ - ä¾› Web/Admin ä½¿ç”¨)
    # ============================================================

    def start_event(self, start_time: str, initial_targets: Dict[str, int],
                    is_abnormal: bool = False, alert_tags: str = "",
                    refine_data: List[Dict] = None) -> Optional[int]:
        """å¼€å§‹æ–°äº‹ä»¶"""
        # PostgreSQL ä¼šè‡ªåŠ¨å°† Python dict/list è½¬ä¸º JSONB
        # ä½†ä¸ºäº†ä¿é™©ï¼Œpsycopg2 é€šå¸¸æ¨èç”¨ Json() åŒ…è£…ï¼Œæˆ–è€…ç›´æ¥ä¼  dict ä¾èµ–é€‚é…å™¨
        sql = """
        INSERT INTO security_events 
        (start_time, end_time, status, target_data, sys_summary, is_abnormal, alert_tags, refine_data)
        VALUES (%s, %s, 'ongoing', %s, %s, %s, %s, %s)
        RETURNING id
        """
        summary = self._fmt_summary(initial_targets)
        refine_json = Json(refine_data) if refine_data else Json([])
        target_json = Json(initial_targets)

        try:
            with self.get_cursor() as cur:
                cur.execute(sql, (
                    start_time, start_time, target_json,
                    summary, is_abnormal, alert_tags, refine_json
                ))
                event_id = cur.fetchone()['id']
                logging.info(f"ğŸ“ [DBManager] äº‹ä»¶åˆ›å»º: ID={event_id}")
                return event_id
        except Exception:
            return None

    def update_event(self, row_id: int, end_time: str, max_targets: Dict[str, int],
                     is_abnormal: Optional[bool] = None, alert_tags: Optional[str] = None):
        """æ›´æ–°äº‹ä»¶"""
        target_json = Json(max_targets)
        summary = self._fmt_summary(max_targets)

        # åŠ¨æ€æ„å»º SQL
        update_fields = ["end_time = %s", "target_data = %s", "sys_summary = %s"]
        params = [end_time, target_json, summary]

        if is_abnormal is not None:
            update_fields.append("is_abnormal = %s")
            params.append(is_abnormal)

        if alert_tags is not None:
            update_fields.append("alert_tags = %s")
            params.append(alert_tags)

        params.append(row_id)
        sql = f"UPDATE security_events SET {', '.join(update_fields)} WHERE id = %s"

        with self.get_cursor() as cur:
            cur.execute(sql, params)

    def search_logs(self, keyword: str = "all", only_abnormal: bool = False,
                    limit: int = 20) -> List[Dict[str, Any]]:
        """æœç´¢æ—¥å¿— (é€‚é… PostgreSQL è¯­æ³•)"""
        sql = """
        SELECT id, start_time, sys_summary, ai_analysis, is_abnormal, 
               target_data, alert_tags, video_path 
        FROM security_events WHERE 1=1
        """
        params = []

        if only_abnormal:
            sql += " AND is_abnormal = TRUE"

        if keyword and keyword.lower() != "all":
            # ç®€å•çš„æ–‡æœ¬æ¨¡ç³Šæœç´¢
            sql += " AND (sys_summary ILIKE %s OR ai_analysis ILIKE %s OR alert_tags ILIKE %s)"
            kw = f"%{keyword}%"
            params.extend([kw, kw, kw])

        sql += " ORDER BY start_time DESC LIMIT %s"
        params.append(limit)

        results = []
        with self.get_cursor(commit=False) as cur:
            cur.execute(sql, params)
            rows = cur.fetchall()

            for row in rows:
                # æ„å»ºå‰ç«¯æ‰€éœ€çš„æ ¼å¼
                desc = row['sys_summary'] or ""
                if row['ai_analysis']:
                    desc += f" | ğŸ¤– {row['ai_analysis']}"

                tags_str = row['alert_tags'] or ""
                if "visual" in tags_str: desc = "ğŸ‘ï¸ " + desc
                if "behavior" in tags_str: desc = "ğŸ§  " + desc

                results.append({
                    "row_id": row['id'],
                    "start_time": str(row['start_time']),  # è½¬å­—ç¬¦ä¸²ä¾›å‰ç«¯æ˜¾ç¤º
                    "description": desc,
                    "is_abnormal": row['is_abnormal'],
                    "targets": row['target_data'],  # psycopg2 è‡ªåŠ¨è½¬å› dict
                    "alert_tags": tags_str,
                    "video_path": row['video_path']
                })
        return results

    # ============================================================
    # å·¥å…·æ–¹æ³•
    # ============================================================

    def _fmt_summary(self, targets: Dict[str, int]) -> str:
        if not targets: return "æ— ç›®æ ‡"
        parts = [f"{k}({v})" for k, v in targets.items()]
        return "å‘ç°: " + ", ".join(parts)

    def close_all(self):
        """å…³é—­è¿æ¥æ± """
        if self._pool:
            self._pool.closeall()
            logging.info("ğŸ”’ [DBManager] è¿æ¥æ± å·²å…³é—­")

    def __del__(self):
        self.close_all()